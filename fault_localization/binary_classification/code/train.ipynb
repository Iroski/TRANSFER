{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from model import BinaryClassifier\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, idx, bs):\n",
    "    x_batch = x[idx: idx+bs]\n",
    "    y_batch = y[idx: idx+bs]\n",
    "    return torch.LongTensor(x_batch), torch.LongTensor(y_batch)\n",
    "\n",
    "\n",
    "def load_from_file(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def print_parameter_statistics(model):\n",
    "    total_num = [p.numel() for p in model.parameters()]\n",
    "    trainable_num = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    print(\"Total parameters: {}\".format(sum(total_num)))\n",
    "    print(\"Trainable parameters: {}\".format(sum(trainable_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix pattern: InsertMissedStmt\n"
     ]
    }
   ],
   "source": [
    "fix_pattern = 'InsertMissedStmt'\n",
    "print(\"Fix pattern: {}\".format(fix_pattern))\n",
    "root = \"../data/{}/\".format(fix_pattern)\n",
    "\n",
    "train_x = load_from_file(os.path.join(root, \"train/x_w2v_new.pkl\"))\n",
    "\n",
    "pretrain_vectors = load_from_file(os.path.join(root, \"vectors.pkl\"))\n",
    "\n",
    "vocab=load_from_file(os.path.join(root, \"vocab.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=train_x[8:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from e_embedding import EnhanceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhanceEmbedding(25613, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding = EnhanceEmbedding(pretrain_vectors.shape[0], pretrain_vectors.shape[1]).cuda()\n",
    "embedding.from_pretrained(torch.from_numpy(pretrain_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ones=[[1,2,3],[3,4,5]]\n",
    "embeded=embedding(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 400, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "del embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.LongTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "et=torch.FloatTensor()\n",
    "at=torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "bt=torch.FloatTensor([[7,8,9],[0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct=torch.cat((et,at),dim=0)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 2, 3] at entry 0 and [2, 2, 3] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0b26f720a7e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 2, 3] at entry 0 and [2, 2, 3] at entry 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('transfer': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22fcc13e4ce33af54b9bfdefb95036e9d5ed01c6c88ad48fe844413e6447d380"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
