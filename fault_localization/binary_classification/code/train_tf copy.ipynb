{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras,RaggedTensor\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense,MaxPool1D,Bidirectional\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_file(file_path):\n",
    "\twith open(file_path, \"rb\") as file:\n",
    "\t\treturn pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedEmbedding(tf.keras.layers.Embedding):\n",
    "    def __init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs):\n",
    "        super().__init__(input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs)\n",
    "        self.five=tf.constant(0.5)\n",
    "    \n",
    "    # @tf.function\n",
    "    def embedding(self,inputs):\n",
    "        return super().call(inputs)\n",
    "    \n",
    "    # @tf.function\n",
    "    def map_2(self,tokens):\n",
    "        identifier=self.embedding(tokens[0])\n",
    "        cur_word=self.embedding(tokens[2])\n",
    "        return tf.squeeze(tf.reduce_mean(identifier)*self.five+cur_word*self.five)\n",
    "    # @tf.function\n",
    "    def map_1(self,inputs):\n",
    "        return tf.map_fn(fn=lambda x :self.map_2(x),elems=inputs,dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        final_embeddings=tf.map_fn(fn=lambda x:self.map_1(x),elems=inputs,dtype=tf.float32)\n",
    "\n",
    "        return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedModel(Model):\n",
    "    def __init__(self,  embedding_dim, hidden_dim, vocab_size, label_size,seq_len, pretrained_weight):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.label_size = label_size\n",
    "        self.activation = tf.keras.activations.tanh\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.embedding=EnhancedEmbedding(vocab_size,embedding_dim,embeddings_initializer=keras.initializers.Constant(pretrained_weight))\n",
    "        # self.encoder = Bidirectional(LSTM(hidden_dim, return_sequences=True))\n",
    "        self.encoder = Bidirectional(LSTM(hidden_dim, return_sequences=True,input_shape=(seq_len,embedding_dim)))\n",
    "        self.pool=MaxPool1D(hidden_dim*2)\n",
    "        self.decoder = Dense(self.label_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # print(\"finish embedding\")\n",
    "        # print(embeddings.shape)\n",
    "        lstm_out = self.encoder(embeddings)\n",
    "        # print(\"finish lstm\")\n",
    "        # print(lstm_out.shape)\n",
    "        lstm_out = tf.transpose(lstm_out, perm=[0,2,1])\n",
    "        # print(lstm_out.shape)\n",
    "        pool_out=self.pool(lstm_out)\n",
    "        # print(\"pool shape\")\n",
    "        # print(pool_out.shape)\n",
    "        out = tf.squeeze(pool_out,[1])\n",
    "        # print(\"finish pool\")\n",
    "        # print(out.shape)\n",
    "        out = self.decoder(out)\n",
    "        # print(\"finish linear\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix pattern: InsertMissedStmt\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "fix_pattern = 'InsertMissedStmt'\n",
    "print(\"Fix pattern: {}\".format(fix_pattern))\n",
    "root = \"../data/{}/\".format(fix_pattern)\n",
    "pretrain_vectors = load_from_file(os.path.join(root, \"vectors.pkl\"))\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "SEQ_LEN=2\n",
    "HIDDEN_DIM = 50\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "LABELS = 2\n",
    "USE_GPU = True\n",
    "MAX_TOKENS = pretrain_vectors.shape[0]\n",
    "EMBEDDING_DIM = pretrain_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = load_from_file(os.path.join(root, \"train/x_w2v_embed_more.pkl\"))\n",
    "val_x = load_from_file(os.path.join(root, \"val/x_w2v_embed_more.pkl\"))\n",
    "test_x = load_from_file(os.path.join(root, \"test/x_w2v_embed_more.pkl\"))\n",
    "\t\n",
    "train_y = load_from_file(os.path.join(root, \"train/y_.pkl\"))\n",
    "val_y = load_from_file(os.path.join(root, \"val/y_.pkl\"))\n",
    "test_y = load_from_file(os.path.join(root, \"test/y_.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x[:64]\n",
    "val_x=val_x[:64]\n",
    "test_x=test_x[:64]\n",
    "\n",
    "train_y=train_y[:64]\n",
    "val_y=val_y[:64]\n",
    "test_y=test_y[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_enc=tf.ragged.constant(train_x,dtype=tf.int32)\n",
    "val_x_enc=tf.ragged.constant(val_x,dtype=tf.int32)\n",
    "test_x_enc=tf.ragged.constant(test_x,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(train_data,val_data,batch_size,embedding_dim, hidden_dim, max_tokens, labels,seq_len, pretrain_weight):\n",
    "    model = EnhancedModel(embedding_dim, hidden_dim, max_tokens, labels,seq_len, pretrain_weight)\n",
    "    model.compile(optimizer=tf.optimizers.Adam(),loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        steps_per_epoch=batch_size,\n",
    "        validation_data=val_data,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[model_checkpoint_callback]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((train_x_enc, train_y))\n",
    "            .repeat()\n",
    "            .shuffle(2048)\n",
    "            .batch(len(train_y)//BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((val_x_enc, val_y))\n",
    "            .batch(len(val_y)//BATCH_SIZE)\n",
    "            .cache()\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "    model=built_model(train_dataset,valid_dataset,BATCH_SIZE,EMBEDDING_DIM, HIDDEN_DIM, MAX_TOKENS, LABELS,SEQ_LEN, pretrain_vectors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((test_x_enc, test_y))\n",
    "            .batch(len(test_y)//BATCH_SIZE)\n",
    "            .cache()\n",
    "            .prefetch(AUTO)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EnhancedModel(EMBEDDING_DIM, HIDDEN_DIM, MAX_TOKENS, LABELS,2, pretrain_vectors)\n",
    "# model.compile(optimizer=tf.optimizers.Adam(),loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=tf.ragged.constant([[[[1,2],[],[2]],[[1,2],[],[2]]],[[[1,2],[],[2]],[[1,2],[],[2]]],[[[1,2],[],[2]],[[1,2],[],[2]]]],dtype=tf.int32)\n",
    "# y=tf.convert_to_tensor([1,0,1],dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2833 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f50d0607080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"enhanced_model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " enhanced_embedding_17 (Enha  multiple                 819616    \n",
      " ncedEmbedding)                                                  \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              multiple                  16600     \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  multiple                 0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 836,222\n",
      "Trainable params: 836,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee88499fdd3a7b1a70753e5f1ce228818dfc3bd0ec28fc81032e87074920dff5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
